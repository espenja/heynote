// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "(_~R[YZw}!O|#V#W!X#[#]#S#^#_#f#a#b%S#d#e&R#f#g&n#g#h&z#h#i'Q#l#m#Y%&x%&y'|~|OX~~!PP#T#U!S~!XOU~~![Q#d#e!b#g#h!m~!eP#d#e!h~!mOT~~!pQ#[#]!v#g#h!h~!yP#T#U!|~#PP#f#g!b~#VP#h#i#Y~#]P#a#b#`~#cP#`#a!h~#iQ#T#U#o#g#h$s~#rP#j#k#u~#xP#T#U#{~$QPT~#g#h$T~$WP#V#W$Z~$^P#f#g$a~$dP#]#^$g~$jP#d#e$m~$pP#h#i!h~$vQ#c#d$|#l#m!h~%PP#b#c!h~%VP#T#U%Y~%]Q#f#g%c#h#i%{~%fP#_#`%i~%lP#W#X%o~%rP#c#d%u~%xP#k#l$|~&OP#[#]!h~&UQ#[#]!b#m#n&[~&_P#h#i&b~&eP#[#]&h~&kP#c#d$|~&qP#i#j&t~&wP#g#h$m~&}P#e#f#`~'TR#X#Y'^#g#h'd#m#n'j~'aP#l#m$m~'gP#l#m!h~'mP#d#e'p~'sP#X#Y'v~'yP#g#h$T~(PP%&x%&y(S~(VP%&x%&y(Y~(_OY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
